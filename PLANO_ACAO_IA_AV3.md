# PLANO DE AÃ‡ÃƒO - PROJETO IA AV3
## Dataset: Appliances Energy Prediction (OpenML ID: 46283)
### Disciplina: InteligÃªncia Artificial Computacional
### Professor: Ms. Cynthia Moreira Maia
### Aluno: Mateus MacÃ¡rio

---

## âš ï¸ REQUISITOS OBRIGATÃ“RIOS (Conforme PDF)

### âŒ PROIBIDO:
- **NÃƒO usar pandas**
- **NÃƒO usar scikit-learn** (nem para algoritmos, nem para nada)
- **NÃƒO usar bibliotecas que implementem os algoritmos**
- Todo cÃ³digo deve ser implementado **MANUALMENTE**

### âœ… OBRIGATÃ“RIO:
- Dataset com **>10 atributos** e **>1000 instÃ¢ncias**
- ImplementaÃ§Ã£o manual de **TODOS** os algoritmos
- ValidaÃ§Ã£o cruzada implementada manualmente
- Entrega dos slides atÃ© **25/11/2025**
- ApresentaÃ§Ã£o **26/11/2025**
- CÃ³digo fonte **OBRIGATÃ“RIO** (sem cÃ³digo = nota zero)

---

## ğŸ“Š DATASET ESCOLHIDO

- **Nome**: Appliances Energy Prediction
- **OpenML ID**: 46283
- **InstÃ¢ncias**: 19,735
- **Atributos**: 28 features + 2 targets
- **Link**: https://www.openml.org/d/46283
- **Justificativa**: Alinhamento com pesquisa sobre eficiÃªncia energÃ©tica e temperatura

---

## ğŸ—‚ï¸ ESTRUTURA DO PROJETO

```
projeto_ia_av3/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â””â”€â”€ appliances_energy.csv
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train_data.npy
â”‚       â”œâ”€â”€ val_data.npy
â”‚       â””â”€â”€ test_data.npy
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ knn.py              # KNN implementado do zero
â”‚   â”‚   â”œâ”€â”€ perceptron.py       # Perceptron implementado do zero
â”‚   â”‚   â”œâ”€â”€ mlp.py              # MLP implementado do zero
â”‚   â”‚   â””â”€â”€ naive_bayes.py      # Naive Bayes implementado do zero
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_loader.py      # Carregamento sem pandas
â”‚   â”‚   â”œâ”€â”€ preprocessing.py     # NormalizaÃ§Ã£o manual
â”‚   â”‚   â”œâ”€â”€ cross_validation.py  # Cross-validation manual
â”‚   â”‚   â”œâ”€â”€ metrics.py          # MÃ©tricas implementadas
â”‚   â”‚   â””â”€â”€ visualization.py    # GrÃ¡ficos com matplotlib
â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”œâ”€â”€ run_knn.py
â”‚   â”‚   â”œâ”€â”€ run_perceptron.py
â”‚   â”‚   â”œâ”€â”€ run_mlp.py
â”‚   â”‚   â””â”€â”€ run_naive_bayes.py
â”‚   â””â”€â”€ main.py                 # Script principal
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ tables/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploratory_analysis.py # AnÃ¡lise sem pandas
â”œâ”€â”€ slides/
â”‚   â””â”€â”€ apresentacao_av3.pptx
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt            # Apenas numpy, matplotlib
```

---

## ğŸ”§ IMPLEMENTAÃ‡ÃƒO DOS ALGORITMOS (100% MANUAL)

### 1. K-Nearest Neighbors (KNN)

```python
class KNN:
    """
    ImplementaÃ§Ã£o manual do KNN
    - SEM uso de sklearn
    - DistÃ¢ncias implementadas manualmente
    """
    
    def __init__(self, k=5, distance='euclidean'):
        self.k = k
        self.distance = distance
        
    def euclidean_distance(self, x1, x2):
        """ImplementaÃ§Ã£o manual da distÃ¢ncia euclidiana"""
        return np.sqrt(np.sum((x1 - x2) ** 2))
    
    def manhattan_distance(self, x1, x2):
        """ImplementaÃ§Ã£o manual da distÃ¢ncia Manhattan"""
        return np.sum(np.abs(x1 - x2))
```

**Tarefas KNN:**
- [ ] Implementar cÃ¡lculo de distÃ¢ncias (Euclidiana e Manhattan)
- [ ] Implementar busca dos k vizinhos mais prÃ³ximos
- [ ] Implementar votaÃ§Ã£o para classificaÃ§Ã£o
- [ ] Testar com k = {3, 5, 7, 9, 11}

### 2. Perceptron

```python
class Perceptron:
    """
    ImplementaÃ§Ã£o manual do Perceptron
    - Treinamento por mÃºltiplas Ã©pocas
    - Taxa de aprendizado configurÃ¡vel
    """
    
    def __init__(self, learning_rate=0.01, n_epochs=100):
        self.lr = learning_rate
        self.n_epochs = n_epochs
        
    def activation(self, x):
        """FunÃ§Ã£o degrau"""
        return 1 if x >= 0 else 0
```

**Tarefas Perceptron:**
- [ ] Implementar inicializaÃ§Ã£o de pesos
- [ ] Implementar forward pass
- [ ] Implementar atualizaÃ§Ã£o de pesos
- [ ] Implementar treinamento por Ã©pocas

### 3. Multi-Layer Perceptron (MLP)

```python
class MLP:
    """
    Rede neural com pelo menos 1 camada oculta
    - Backpropagation implementado manualmente
    - Sem uso de frameworks
    """
    
    def __init__(self, input_size, hidden_size, output_size):
        self.W1 = np.random.randn(input_size, hidden_size) * 0.01
        self.b1 = np.zeros((1, hidden_size))
        self.W2 = np.random.randn(hidden_size, output_size) * 0.01
        self.b2 = np.zeros((1, output_size))
```

**Tarefas MLP:**
- [ ] Implementar forward propagation
- [ ] Implementar funÃ§Ãµes de ativaÃ§Ã£o (sigmoid/ReLU)
- [ ] Implementar backpropagation
- [ ] Implementar gradiente descendente

### 4. Naive Bayes

```python
class NaiveBayes:
    """
    ImplementaÃ§Ã£o manual do Naive Bayes
    - VersÃ£o univariada
    - VersÃ£o multivariada
    """
    
    def __init__(self, variant='gaussian'):
        self.variant = variant
        
    def gaussian_pdf(self, x, mean, std):
        """FunÃ§Ã£o densidade de probabilidade Gaussiana"""
        exponent = np.exp(-((x - mean) ** 2) / (2 * std ** 2))
        return (1 / (np.sqrt(2 * np.pi) * std)) * exponent
```

**Tarefas Naive Bayes:**
- [ ] Implementar cÃ¡lculo de probabilidades a priori
- [ ] Implementar likelihood para variÃ¡veis contÃ­nuas
- [ ] Implementar versÃ£o univariada
- [ ] Implementar versÃ£o multivariada

---

## ğŸ“ˆ MÃ‰TRICAS DE AVALIAÃ‡ÃƒO (Implementadas Manualmente)

```python
def accuracy(y_true, y_pred):
    """AcurÃ¡cia implementada manualmente"""
    correct = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i])
    return correct / len(y_true)

def precision_score(y_true, y_pred):
    """PrecisÃ£o implementada manualmente"""
    # Implementar cÃ¡lculo de TP, FP
    pass

def f1_score(y_true, y_pred):
    """F1-Score implementado manualmente"""
    # Implementar usando precision e recall
    pass
```

---

## ğŸ”„ VALIDAÃ‡ÃƒO CRUZADA (Manual)

```python
def k_fold_cross_validation(X, y, k=5):
    """
    ImplementaÃ§Ã£o manual de k-fold cross-validation
    SEM uso de sklearn
    """
    n_samples = len(X)
    fold_size = n_samples // k
    indices = list(range(n_samples))
    
    for i in range(k):
        # Separar manualmente treino e validaÃ§Ã£o
        val_start = i * fold_size
        val_end = val_start + fold_size
        # ... implementaÃ§Ã£o completa
```

---

## ğŸ“… CRONOGRAMA DE DESENVOLVIMENTO

### Semana 1: 20-24 de Novembro

#### Dia 1 (20/11) - Setup e Carregamento
- [ ] Baixar dataset do OpenML (usando requests ou urllib)
- [ ] Implementar leitor CSV manual (sem pandas)
- [ ] Converter dados para numpy arrays
- [ ] Verificar dimensÃµes e tipos de dados

#### Dia 2 (21/11) - AnÃ¡lise e PrÃ©-processamento
- [ ] EstatÃ­sticas bÃ¡sicas (mÃ©dia, desvio padrÃ£o) - manual
- [ ] Identificar missing values
- [ ] NormalizaÃ§Ã£o manual (min-max ou z-score)
- [ ] SeparaÃ§Ã£o treino/validaÃ§Ã£o/teste (60/20/20)

#### Dia 3 (22/11) - ImplementaÃ§Ã£o KNN
- [ ] Classe KNN completa
- [ ] DistÃ¢ncias Euclidiana e Manhattan
- [ ] Teste com diferentes valores de k
- [ ] MediÃ§Ã£o de tempo de execuÃ§Ã£o

#### Dia 4 (23/11) - ImplementaÃ§Ã£o Perceptron e MLP
- [ ] Perceptron com mÃºltiplas Ã©pocas
- [ ] MLP com backpropagation
- [ ] Teste de diferentes arquiteturas

#### Dia 5 (24/11) - Naive Bayes e ValidaÃ§Ã£o Cruzada
- [ ] Implementar Naive Bayes (univariado e multivariado)
- [ ] Implementar k-fold cross-validation manual
- [ ] Aplicar em todos os modelos

### Semana 2: 25-26 de Novembro

#### Dia 6 (25/11) - Resultados e Slides
- [ ] Calcular todas as mÃ©tricas
- [ ] Gerar tabela comparativa (formato do PDF)
- [ ] Criar grÃ¡ficos de desempenho
- [ ] **ENTREGAR SLIDES atÃ© 23:59**

#### Dia 7 (26/11) - ApresentaÃ§Ã£o
- [ ] RevisÃ£o final do cÃ³digo
- [ ] **APRESENTAÃ‡ÃƒO**

---

## ğŸ“Š TABELA DE RESULTADOS (Modelo do PDF)

| Classificador | AcurÃ¡cia | PrecisÃ£o | F1-Score | Tempo Treino (s) | Tempo Teste (s) |
|--------------|----------|----------|----------|------------------|-----------------|
| K-vizinhos (Dist. Euclidiana) | 0.XX Â± 0.XX | 0.XX Â± 0.XX | 0.XX Â± 0.XX | X.XX Â± X.XX | X.XX Â± X.XX |
| K-vizinhos (Dist. Manhattan) | 0.XX Â± 0.XX | 0.XX Â± 0.XX | 0.XX Â± 0.XX | X.XX Â± X.XX | X.XX Â± X.XX |
| Perceptron | 0.XX Â± 0.XX | 0.XX Â± 0.XX | 0.XX Â± 0.XX | X.XX Â± X.XX | X.XX Â± X.XX |
| MLP | 0.XX Â± 0.XX | 0.XX Â± 0.XX | 0.XX Â± 0.XX | X.XX Â± X.XX | X.XX Â± X.XX |
| Bayesiano (Univariado) | 0.XX Â± 0.XX | 0.XX Â± 0.XX | 0.XX Â± 0.XX | X.XX Â± X.XX | X.XX Â± X.XX |
| Bayesiano (Multivariado) | 0.XX Â± 0.XX | 0.XX Â± 0.XX | 0.XX Â± 0.XX | X.XX Â± X.XX | X.XX Â± X.XX |

---

## ğŸ¯ ESTRUTURA DOS SLIDES

### Slides ObrigatÃ³rios:
1. **Capa**: TÃ­tulo, Nome, Data
2. **IntroduÃ§Ã£o**: Dataset escolhido e justificativa
3. **Banco de Dados**: 
   - DescriÃ§Ã£o das features
   - EstatÃ­sticas bÃ¡sicas
   - RelaÃ§Ã£o com eficiÃªncia energÃ©tica
4. **Algoritmos**:
   - ExplicaÃ§Ã£o de cada algoritmo
   - Trechos de cÃ³digo principais
5. **MÃ©tricas de AvaliaÃ§Ã£o**:
   - ExplicaÃ§Ã£o de Accuracy, Precision, F1-Score
6. **Resultados**:
   - Tabela comparativa
   - GrÃ¡ficos de desempenho
7. **AnÃ¡lise Comparativa**:
   - ComparaÃ§Ã£o das mÃ©tricas
   - Tempos de treino e teste
   - RelaÃ§Ã£o desempenho/eficiÃªncia
8. **ConclusÃµes**:
   - Melhor classificador
   - Pontos fortes e limitaÃ§Ãµes

---

## ğŸš€ CÃ“DIGO INICIAL PARA COMEÃ‡AR

### data_loader.py (SEM PANDAS!)
```python
import csv
import numpy as np

def load_csv_manual(filepath):
    """
    Carrega CSV sem usar pandas
    """
    data = []
    with open(filepath, 'r') as file:
        csv_reader = csv.reader(file)
        header = next(csv_reader)
        for row in csv_reader:
            data.append([float(val) for val in row])
    return np.array(data), header

def train_test_split_manual(X, y, test_size=0.2, random_seed=42):
    """
    Split manual sem sklearn
    """
    np.random.seed(random_seed)
    n_samples = len(X)
    n_test = int(n_samples * test_size)
    
    indices = np.random.permutation(n_samples)
    test_indices = indices[:n_test]
    train_indices = indices[n_test:]
    
    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]
```

---

## âš ï¸ CHECKLIST FINAL

### Antes da Entrega:
- [ ] **SEM pandas** em nenhum lugar do cÃ³digo
- [ ] **SEM scikit-learn** em nenhum lugar do cÃ³digo
- [ ] Todos os algoritmos implementados manualmente
- [ ] ValidaÃ§Ã£o cruzada implementada manualmente
- [ ] MÃ©tricas implementadas manualmente
- [ ] CÃ³digo comentado e organizado
- [ ] Tabela de resultados com mÃ©dia Â± desvio padrÃ£o
- [ ] Tempos de execuÃ§Ã£o medidos

### VerificaÃ§Ã£o de PlÃ¡gio:
- [ ] CÃ³digo original (nÃ£o copiado da internet)
- [ ] Sem uso de ChatGPT/Copilot para gerar algoritmos completos
- [ ] ImplementaÃ§Ãµes prÃ³prias documentadas

---

## ğŸ“ NOTAS IMPORTANTES

1. **Pontualidade**: Atraso = penalizaÃ§Ã£o
2. **CÃ³digo obrigatÃ³rio**: Sem cÃ³digo = nota zero
3. **ApresentaÃ§Ã£o**: Se nÃ£o apresentar, agendar avaliaÃ§Ã£o individual
4. **Originalidade**: SerÃ¡ verificado plÃ¡gio e uso de IA

---

## ğŸ”— LINKS ÃšTEIS

- Dataset: https://www.openml.org/d/46283
- FormulÃ¡rio de escolha: https://forms.gle/X5hF8WUqpFBdXSXx9
- OpenML API (para download): https://docs.openml.org/

---

## ğŸ’¡ DICAS DE IMPLEMENTAÃ‡ÃƒO

1. **ComeÃ§ar simples**: Primeiro fazer funcionar, depois otimizar
2. **Testar incrementalmente**: Testar cada funÃ§Ã£o individualmente
3. **Documentar bem**: ComentÃ¡rios explicando a lÃ³gica
4. **Versionar cÃ³digo**: Usar git desde o inÃ­cio
5. **Medir tempos**: Usar time.time() para cronometrar

---

*Documento criado para exportaÃ§Ã£o ao VS Code - Projeto IA AV3*
