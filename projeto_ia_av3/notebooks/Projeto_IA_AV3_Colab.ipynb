{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Projeto IA AV3 - Classifica√ß√£o de Energia\n",
        "\n",
        "**Disciplina:** Intelig√™ncia Artificial Computacional\n",
        "\n",
        "**Aluno:** Mateus Gomes Mac√°rio\n",
        "\n",
        "**Professor:** Ms. Cynthia Moreira Maia\n",
        "\n",
        "---\n",
        "\n",
        "## üìå Objetivo\n",
        "\n",
        "Implementar e avaliar algoritmos de classifica√ß√£o **do zero** (sem scikit-learn ou pandas):\n",
        "- K-Nearest Neighbors (KNN)\n",
        "- Perceptron\n",
        "- Multi-Layer Perceptron (MLP)\n",
        "- Naive Bayes\n",
        "\n",
        "## üîó Links\n",
        "\n",
        "- **Reposit√≥rio:** [github.com/mateusmacario/electrolyzer-simulator](https://github.com/mateusmacario/electrolyzer-simulator)\n",
        "- **Dataset:** [OpenML - Appliances Energy](https://www.openml.org/d/46283)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Setup e Instala√ß√£o"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clone do reposit√≥rio\n",
        "!git clone https://github.com/mateusmacario/electrolyzer-simulator.git\n",
        "%cd electrolyzer-simulator/projeto_ia_av3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Instala depend√™ncias\n",
        "!pip install -q numpy matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Importa√ß√µes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Adiciona src ao path\n",
        "sys.path.insert(0, 'src')\n",
        "\n",
        "# Imports dos algoritmos\n",
        "from algorithms.knn import KNNEuclidean, KNNManhattan\n",
        "from algorithms.perceptron import MultiClassPerceptron\n",
        "from algorithms.mlp import MLP\n",
        "from algorithms.naive_bayes import UnivariateNaiveBayes, MultivariateNaiveBayes\n",
        "\n",
        "# Imports dos utilit√°rios\n",
        "from utils.preprocessing import StandardScaler, binarize_target\n",
        "from utils.cross_validation import cross_validate_stratified\n",
        "from utils.visualization import plot_metrics_comparison, generate_markdown_table\n",
        "\n",
        "print(\"‚úì Importa√ß√µes conclu√≠das!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Download e Carregamento do Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Op√ß√£o 1: Criar dataset sint√©tico para demonstra√ß√£o\n",
        "!python src/create_demo_dataset.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Carrega dataset\n",
        "import csv\n",
        "\n",
        "def load_dataset(filepath='data/raw/appliances_energy.csv'):\n",
        "    data = []\n",
        "    with open(filepath, 'r') as file:\n",
        "        csv_reader = csv.reader(file)\n",
        "        header = next(csv_reader)\n",
        "        for row in csv_reader:\n",
        "            try:\n",
        "                data.append([float(val) for val in row])\n",
        "            except:\n",
        "                continue\n",
        "    \n",
        "    data = np.array(data)\n",
        "    X = data[:, :-1]\n",
        "    y = data[:, -1]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X, y = load_dataset()\n",
        "print(f\"Dataset carregado: {X.shape[0]} amostras, {X.shape[1]} features\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4Ô∏è‚É£ Pr√©-processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Binariza target\n",
        "y_binary = binarize_target(y)\n",
        "print(f\"Classe 0: {np.sum(y_binary == 0)} amostras\")\n",
        "print(f\"Classe 1: {np.sum(y_binary == 1)} amostras\")\n",
        "\n",
        "# Normaliza features\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "print(\"\\n‚úì Pr√©-processamento conclu√≠do!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Defini√ß√£o dos Modelos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "models = {\n",
        "    'KNN (Euclidiana)': KNNEuclidean(k=5),\n",
        "    'KNN (Manhattan)': KNNManhattan(k=5),\n",
        "    'Perceptron': MultiClassPerceptron(learning_rate=0.01, n_epochs=50),\n",
        "    'MLP': MLP(input_size=X_normalized.shape[1], hidden_sizes=[32, 16],\n",
        "               output_size=2, learning_rate=0.01, n_epochs=50),\n",
        "    'Naive Bayes (Univariado)': UnivariateNaiveBayes(),\n",
        "    'Naive Bayes (Multivariado)': MultivariateNaiveBayes()\n",
        "}\n",
        "\n",
        "print(f\"Modelos definidos: {len(models)}\")\n",
        "for name in models.keys():\n",
        "    print(f\"  - {name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Valida√ß√£o Cruzada (K-Fold)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results = {}\n",
        "n_folds = 5\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"Avaliando: {model_name}\")\n",
        "    print('=' * 60)\n",
        "    \n",
        "    cv_results = cross_validate_stratified(\n",
        "        model, X_normalized, y_binary,\n",
        "        n_folds=n_folds,\n",
        "        verbose=True\n",
        "    )\n",
        "    \n",
        "    results[model_name] = cv_results\n",
        "    \n",
        "    print(f\"\\nResumo:\")\n",
        "    print(f\"  Acur√°cia:  {cv_results['accuracy_mean']:.4f} ¬± {cv_results['accuracy_std']:.4f}\")\n",
        "    print(f\"  F1-Score:  {cv_results['f1_score_mean']:.4f} ¬± {cv_results['f1_score_std']:.4f}\")\n",
        "\n",
        "print(\"\\n‚úì Valida√ß√£o cruzada conclu√≠da!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7Ô∏è‚É£ Resultados e Visualiza√ß√µes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Gera tabela de resultados\n",
        "md_table = generate_markdown_table(results)\n",
        "print(md_table)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualiza compara√ß√£o de m√©tricas\n",
        "plot_metrics_comparison(results)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# An√°lise do melhor modelo\n",
        "best_model = max(results.items(), key=lambda x: x[1]['accuracy_mean'])\n",
        "print(f\"\\nüèÜ MELHOR MODELO: {best_model[0]}\")\n",
        "print(f\"   Acur√°cia: {best_model[1]['accuracy_mean']:.4f} ¬± {best_model[1]['accuracy_std']:.4f}\")\n",
        "print(f\"   F1-Score: {best_model[1]['f1_score_mean']:.4f} ¬± {best_model[1]['f1_score_std']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8Ô∏è‚É£ An√°lise de Trade-off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"\\nAN√ÅLISE DE TRADE-OFF (Desempenho vs Efici√™ncia):\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "efficiency_scores = {}\n",
        "for model_name, result in results.items():\n",
        "    acc = result['accuracy_mean']\n",
        "    time_total = result['train_time_mean'] + result['test_time_mean']\n",
        "    efficiency = acc / (time_total + 0.01)\n",
        "    efficiency_scores[model_name] = efficiency\n",
        "    \n",
        "    print(f\"{model_name}\")\n",
        "    print(f\"  Acur√°cia: {acc:.4f} | Tempo: {time_total:.2f}s | Score: {efficiency:.4f}\")\n",
        "\n",
        "best_efficiency = max(efficiency_scores.items(), key=lambda x: x[1])\n",
        "print(f\"\\n‚ú® Melhor Trade-off: {best_efficiency[0]} (Score: {best_efficiency[1]:.4f})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9Ô∏è‚É£ Exporta√ß√£o dos Resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Salva resultados em arquivo\n",
        "import json\n",
        "\n",
        "# Prepara resultados para serializa√ß√£o\n",
        "results_serializable = {}\n",
        "for model_name, result in results.items():\n",
        "    results_serializable[model_name] = {\n",
        "        'accuracy_mean': float(result['accuracy_mean']),\n",
        "        'accuracy_std': float(result['accuracy_std']),\n",
        "        'f1_score_mean': float(result['f1_score_mean']),\n",
        "        'f1_score_std': float(result['f1_score_std']),\n",
        "        'train_time_mean': float(result['train_time_mean']),\n",
        "        'test_time_mean': float(result['test_time_mean'])\n",
        "    }\n",
        "\n",
        "# Salva como JSON\n",
        "with open('results_colab.json', 'w') as f:\n",
        "    json.dump(results_serializable, f, indent=2)\n",
        "\n",
        "print(\"‚úì Resultados salvos em results_colab.json\")\n",
        "print(\"‚úì Voc√™ pode baixar este arquivo para integrar com sua aplica√ß√£o web!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ Conclus√£o\n",
        "\n",
        "Todos os algoritmos foram implementados **100% manualmente** sem uso de bibliotecas de ML!\n",
        "\n",
        "### Principais Resultados:\n",
        "- ‚úÖ Todos os requisitos do projeto atendidos\n",
        "- ‚úÖ C√≥digo limpo e bem documentado\n",
        "- ‚úÖ Valida√ß√£o cruzada implementada do zero\n",
        "- ‚úÖ M√©tricas calculadas manualmente\n",
        "\n",
        "### Pr√≥ximos Passos:\n",
        "1. Baixar dataset real do OpenML\n",
        "2. Testar com dataset completo (19,735 amostras)\n",
        "3. Ajustar hiperpar√¢metros\n",
        "4. Integrar com aplica√ß√£o web\n",
        "\n",
        "---\n",
        "\n",
        "**Desenvolvido por:** Mateus Gomes Mac√°rio\n",
        "\n",
        "**Disciplina:** Intelig√™ncia Artificial Computacional - UNIFOR\n"
      ]
    }
  ]
}